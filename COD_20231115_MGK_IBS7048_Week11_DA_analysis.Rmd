---
title: "COD_20231107_MGK_IBS7048_week11_DA_analysis"
author: "Minsik Kim"
date: "2023-11-08"
output:
        rmdformats::downcute:
        downcute_theme: "chaos"
codeolding: show
fig_width: 6
fig_height: 6
df_print: paged
editor_options: 
        chunk_output_type: inline
markdown: 
        wrap: 72
---
        
```{r warning=FALSE, message=FALSE, echo=FALSE, results='hide', setup}
#===============================================================================
#BTC.LineZero.Header.1.1.0
#===============================================================================
#R Markdown environment setup and reporting utility.
#===============================================================================
#RLB.Dependencies:
#   knitr, magrittr, pacman, rio, rmarkdown, rmdformats, tibble, yaml
#===============================================================================
#Input for document parameters, libraries, file paths, and options.
#=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=
knitr::opts_chunk$set(message=FALSE, warning = FALSE)

path_working <- "/Users/minsikkim/Dropbox (Personal)/Inha/5_Lectures/Advanced metagenomics/scripts/IBS7048_Advanced_metagenomics/"
path_library <- "/Library/Frameworks/R.framework/Resources/library"
str_libraries <- c("tidyverse", "pacman", "yaml", "knitr", "rmarkdown", "rmdformats")


YAML_header <-
        '---
title: "COD_20231101_MGK_IBS7048_week11_statistical_microbiome_analysis"
author: "Minsik Kim"
date: "2032.11.08"
output:
    rmdformats::downcute:
        downcute_theme: "chaos"
        codeolding: hide
        fig_width: 6
        fig_height: 6
---'
seed <- "20230920"

#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
#Loads libraries, file paths, and other document options.
#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
FUN.LineZero.Boot <- function() {
        .libPaths(path_library)
        
        require(pacman)
        pacman::p_load(c("knitr", "rmarkdown", "rmdformats", "yaml","ggpubr"))
        
        knitr::opts_knit$set(root.dir = path_working)
        
        str_libraries |> unique() |> sort() -> str_libraries
        pacman::p_load(char = str_libraries)
        
        set.seed(seed)
}
FUN.LineZero.Boot()
#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
#Outputs R environment report.
#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
FUN.LineZero.Report <- function() {
        cat("Line Zero Environment:\n\n")
        paste("R:", pacman::p_version(), "\n") |> cat()
        cat("Libraries:\n")
        for (str_libraries in str_libraries) {
                paste(
                        "    ", str_libraries, ": ", pacman::p_version(package = str_libraries),
                        "\n", sep = ""
                ) |> cat()
        }
        paste("\nOperating System:", pacman::p_detectOS(), "\n") |> cat()
        paste("    Library Path:", path_library, "\n") |> cat()
        paste("    Working Path:", path_working, "\n") |> cat()
        paste("Seed:", seed, "\n\n") |> cat()
        cat("YAML Header:\n")
        cat(YAML_header)
}
FUN.LineZero.Report()


```

This analysis pipe noted https://github.com/minsiksudo/BTE3207_Advanced_Biostatistics.


# Roading the data

from previous lecture.. we generated a phyloseq object. it can be saved to hard disk using the below command.

`saveRDS(ps, "phyloseq_example.rds")`

And it can be loaded to a new R session like below!

```{r}

getwd()

library(phyloseq)
library(tidyverse)
library(microbiome)
library(vegan)
library(ggplot2)
#source("https://raw.githubusercontent.com/joey711/phyloseq/master/inst/scripts/installer.R",
#       local = TRUE)


phyloseq <- readRDS("/Users/minsikkim/Dropbox (Personal)/Inha/5_Lectures/Advanced metagenomics/scripts/IBS7048_Advanced_metagenomics/phyloseq_example.rds")


phyloseq_rel <- transform_sample_counts(phyloseq, function(x){x/sum(x)})
```


# Differential abundance analysis using your model

## Using linear models 1


```{r}




#Loading OTU table

otu_table <- phyloseq_rel %>% otu_table %>% t
        
#tax table for different sample type
taxa_data <- otu_table[1] %>% t %>% data.frame()

#Making a merged dataframe having sample data and CLR transformed output
lme_data <- merge(taxa_data, sample_data(phyloseq_rel), by = 0) %>% column_to_rownames("Row.names")


ggplot(lme_data, aes(x = Day, y = ASV1)) +
        geom_point()


lm(ASV1 ~ When, data = lme_data) %>%
        summary()
 

```

## Using linear models 2

```{r}


#Loading OTU table

otu_table <- phyloseq_rel %>% otu_table %>% t
        
#tax table for different sample type
taxa_data <- otu_table[2] %>% t %>% data.frame()

#Making a merged dataframe having sample data and CLR transformed output
lme_data <- merge(taxa_data, sample_data(phyloseq_rel), by = 0) %>% column_to_rownames("Row.names")


ggplot(lme_data, aes(x = Day, y = ASV2)) +
        geom_point()


lm(ASV2 ~ When, data = lme_data) %>%
        summary()
 

```

## Introduction to for loop

```{r}

for(i in 1:10) {
        print(i)
}


```


```{r}

x = 0

for(i in 1:10) {
        x <- x + i
        print(x + i)
}


```

## For-loop for analysis result aggregation


```{r}

#with all samples

lm_taxa_all <- data.frame()

for(i in 1:1) {
        #Creating a data frame that includes CLR transformed data of i-th bug.
        #making differnt otu tables for each sample type
        otu_table <- phyloseq_rel %>% otu_table
        
        #tax table for different sample type
        taxa_data <- otu_table[,i] %>% data.frame()
        
        #Making a merged dataframe having sample data and CLR transformed output
        lm_data <- merge(taxa_data, sample_data(phyloseq_rel), by = 0) %>% column_to_rownames("Row.names")
        
        #generating a character of formula.
        #Here, as the taxa are already CLR transformed, I did not make model at log-scale.
        lmformula <- paste(names(taxa_data), "~", "When")
        
        #BAL stratified analysis
        all_result <- lm(formula = lmformula,
                                 data = lm_data) %>% 
                summary %>%
                .$coefficients %>%
                data.frame(check.names = F) %>% 
                mutate(feature = names(taxa_data)) %>% 
                rownames_to_column("value") %>%
                .[2,] %>%
                remove_rownames()
        #row binding all the associations of i-th taxa to one data frame
        lm_taxa_all <- rbind(lm_taxa_all,
                               all_result) %>% 
                remove_rownames()
        
}

lm_taxa_all



```

## For-loop for DA analysis

```{r}


#with all samples

lm_taxa_all <- data.frame()

all <- phyloseq_rel %>% taxa_sums() %>% length()

for(i in 1:all) {
        #Creating a data frame that includes CLR transformed data of i-th bug.
        #making differnt otu tables for each sample type
        otu_table <- phyloseq_rel %>% otu_table
        
        #tax table for different sample type
        taxa_data <- otu_table[,i] %>% data.frame()
        
        #Making a merged dataframe having sample data and CLR transformed output
        lm_data <- merge(taxa_data, sample_data(phyloseq_rel), by = 0) %>% column_to_rownames("Row.names")
        
        #generating a character of formula.
        #Here, as the taxa are already CLR transformed, I did not make model at log-scale.
        lmformula <- paste(names(taxa_data), "~", "When")
        
        #BAL stratified analysis
        all_result <- lm(formula = lmformula,
                                 data = lm_data) %>% 
                summary %>%
                .$coefficients %>%
                data.frame(check.names = F) %>% 
                mutate(feature = names(taxa_data)) %>% 
                rownames_to_column("value") %>%
                .[2,] %>%
                remove_rownames()
        #row binding all the associations of i-th taxa to one data frame
        lm_taxa_all <- rbind(lm_taxa_all,
                               all_result) %>% 
                remove_rownames()
        
}


lm_taxa_all <- lm_taxa_all %>%
        subset(., !is.nan(.$`Pr(>|t|)`)) %>%
        mutate(qval = qvalue::qvalue(`Pr(>|t|)`, lambda = 0)$qvalue,
               p_bh = p.adjust(p = `Pr(>|t|)`, method = "BH"))  
#Benjamini-Hochberg correction



lm_taxa_all

```

volcano plot

```{r}

ggplot(lm_taxa_all, aes(x = Estimate, y = -log10(p_bh))) +
        geom_point() +
        geom_hline(yintercept = -log10(0.05), col = "red") +
        annotate("text", x = 0.05, y = 1.5, label = "p-value = 0.05", col = "red")

```


## For-loop for DA analysis (transformed data)

```{r}

phyloseq_clr <- microbiome::transform(phyloseq, transform = "clr")

#with all samples

lm_taxa_all <- data.frame()

all <- phyloseq_clr %>% taxa_sums() %>% length()

for(i in 1:all) {
        #Creating a data frame that includes CLR transformed data of i-th bug.
        #making differnt otu tables for each sample type
        otu_table <- phyloseq_clr %>% otu_table
        
        #tax table for different sample type
        taxa_data <- otu_table[,i] %>% data.frame()
        
        #Making a merged dataframe having sample data and CLR transformed output
        lm_data <- merge(taxa_data, sample_data(phyloseq_clr), by = 0) %>% column_to_rownames("Row.names")
        
        #generating a character of formula.
        #Here, as the taxa are already CLR transformed, I did not make model at log-scale.
        lmformula <- paste(names(taxa_data), "~", "When")
        
        #BAL stratified analysis
        all_result <- lm(formula = lmformula,
                                 data = lm_data) %>% 
                summary %>%
                .$coefficients %>%
                data.frame(check.names = F) %>% 
                mutate(feature = names(taxa_data)) %>% 
                rownames_to_column("value") %>%
                .[2,] %>%
                remove_rownames()
        #row binding all the associations of i-th taxa to one data frame
        lm_taxa_all <- rbind(lm_taxa_all,
                               all_result) %>% 
                remove_rownames()
        
}


lm_taxa_all <- lm_taxa_all %>%
        subset(., !is.nan(.$`Pr(>|t|)`)) %>%
        mutate(qval = qvalue::qvalue(`Pr(>|t|)`, lambda = 0)$qvalue,
               p_bh = p.adjust(p = `Pr(>|t|)`, method = "BH"))  
#Benjamini-Hochberg correction



lm_taxa_all

```

volcano plot

```{r}

ggplot(lm_taxa_all, aes(x = Estimate, y = -log10(p_bh))) +
        geom_point() +
        geom_hline(yintercept = -log10(0.05), col = "red") +
        annotate("text", x = 0.05, y = 1.5, label = "p-value = 0.05", col = "red")

```

Volcano plot looks ok.



#Using MaAslin


MaAsLin2 is comprehensive R package for efficiently determining multivariable association between phenotypes, environments, exposures, covariates and microbial meta’omic features. MaAsLin2 relies on general linear models to accommodate most modern epidemiological study designs, including cross-sectional and longitudinal, and offers a variety of data exploration, normalization, and transformation methods.



https://huttenhower.sph.harvard.edu/maaslin/



```{r}

if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("Maaslin2")


library(Maaslin2)


```

Running maaslin

```{r}
capture.output(
        maaslin_output<-
                Maaslin2(input_data = otu_table(phyloseq_rel) %>% 
                                 data.frame(),
                         input_metadata = phyloseq_rel %>%
                                 sample_data %>% 
                                 data.frame(check.names = F), 
                output = paste0(getwd(), "/maaslin_output") ,
                fixed_effects = c("When"), 
                transform = "LOG", #default
                normalization = "TSS", #Choose your own normalization method
                reference = c("When,Early")))

maaslin_all <- read.csv(paste0(getwd(), "/maaslin_output/all_results.tsv"), sep = "\t")

maaslin_all



```

Volcano plot of MaAslin output

```{r}

ggplot(maaslin_all, aes(x = coef, y = -log10(qval))) +
        geom_point() +
        geom_hline(yintercept = -log10(0.05), col = "red") +
        annotate("text", x = 0.1, y = 1.5, label = "q-value = 0.1", col = "red")

```

```{r}

install.packages("devtools")
library(devtools)

devtools::install_github("slowkow/ggrepel")


library(ggrepel)

ggplot(maaslin_all, aes(x = coef, y = -log10(qval))) +
        geom_point() +
        geom_hline(yintercept = -log10(0.05), col = "red") +
        annotate("text", x = 0.1, y = 1.5, label = "q-value = 0.1", col = "red") +
        geom_text_repel(aes(label = feature)) +
        theme_classic()    

```

# Using SIAMCAT

Due to limited number of samples / metadat in our dataset, we are going to use examples et from SIAMCAT pacakge.

**https://siamcat.embl.de/articles/SIAMCAT_vignette.html*

```{r}

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("SIAMCAT")

#or,

#require("devtools")
#devtools::install_github(repo = 'zellerlab/siamcat')

library(SIAMCAT)

```

Loading example data set

```{r}


data("feat_crc_zeller", package="SIAMCAT")
data("meta_crc_zeller", package="SIAMCAT")

siamcat_feature <- feat.crc.zeller
siamcat_meta <- meta.crc.zeller


```


```{r}

dim(siamcat_feature)

```

```{r}
siamcat_label <- create.label(meta=siamcat_meta,
    label='Group', case='CRC')

siamcat_label
```

Creating a SIAMCAT object

```{r}


sc.obj <- siamcat(feat=siamcat_feature,
    label=siamcat_label,
    meta=siamcat_meta)

sc.obj

```

Filtering low abundant taxta

```{r}

sc.obj <- filter.features(sc.obj,
    filter.method = 'abundance',
    cutoff = 0.001)
```

Testing associations

```{r}
sc.obj <- check.associations(sc.obj, log.n0 = 1e-06, alpha = 0.05)

association.plot(sc.obj, sort.by = 'fc', 
                panels = c('fc', 'prevalence', 'auroc'))
```

Confounder testing


```{r}

check.confounders(sc.obj, fn.plot = 'confounder_plots.pdf',
                    meta.in = NULL, feature.type = 'filtered')

```

Data normalization

```{r}

sc.obj <- normalize.features(sc.obj, norm.method = "log.unit",
    norm.param = list(log.n0 = 1e-06, n.p = 2,norm.margin = 1))

```

Cross-validation preparing


```{r}
sc.obj <-  create.data.split(sc.obj, num.folds = 5, num.resample = 2)

```

Training model using *lasso* (least absolute shrinkage and selection operator; also Lasso or LASSO), a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the resulting statistical model. 


*Lasso* is a supervised regularization method used in *machine learning*.

`method = ` specifies the type of model to be trained, may be one of these:

`c('lasso', 'enet', 'ridge', 'lasso_ll', 'ridge_ll', 'randomForest')`



```{r}
#Model training
sc.obj.lasso <- train.model(sc.obj, method = "lasso")

```


Model evaluation

Lasso

```{r}
#Making predictions
sc.obj.lasso <- make.predictions(sc.obj.lasso)
sc.obj.lasso <-  evaluate.predictions(sc.obj.lasso)
model.evaluation.plot(sc.obj.lasso)

```

Making interpretation plot

```{r}
model.interpretation.plot(sc.obj.lasso, fn.plot = 'interpretation.pdf',
    consens.thres = 0.5, limits = c(-3, 3), heatmap.type = 'zscore')

```

# Bibliography

```{r warning=FALSE, message=FALSE, echo=FALSE}
#===============================================================================
#BTC.LineZero.Footer.1.1.0
#===============================================================================
#R markdown citation generator.
#===============================================================================
#RLB.Dependencies:
#   magrittr, pacman, stringr
#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
#BTC.Dependencies:
#   LineZero.Header
#===============================================================================
#Generates citations for each explicitly loaded library.
#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
str_libraries <- c("r", str_libraries)
for (str_libraries in str_libraries) {
        str_libraries |>
                pacman::p_citation() |>
                print(bibtex = FALSE) |>
                capture.output() %>%
                .[-1:-3] %>% .[. != ""] |>
                stringr::str_squish() |>
                stringr::str_replace("_", "") |>
                cat()
        cat("\n")
}
#===============================================================================
```
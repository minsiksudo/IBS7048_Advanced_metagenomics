---
title: "COD_20231115_MGK_IBS7048_week12_DA_analysis"
author: "Minsik Kim"
date: "2023-11-15"
output:
        rmdformats::downcute:
        downcute_theme: "chaos"
codeolding: show
fig_width: 6
fig_height: 6
df_print: paged
editor_options: 
        chunk_output_type: inline
markdown: 
        wrap: 72
---
        
```{r warning=FALSE, message=FALSE, echo=FALSE, results='hide', setup}
#===============================================================================
#BTC.LineZero.Header.1.1.0
#===============================================================================
#R Markdown environment setup and reporting utility.
#===============================================================================
#RLB.Dependencies:
#   knitr, magrittr, pacman, rio, rmarkdown, rmdformats, tibble, yaml
#===============================================================================
#Input for document parameters, libraries, file paths, and options.
#=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=
knitr::opts_chunk$set(message=FALSE, warning = FALSE)

path_working <- "/Users/minsikkim/Dropbox (Personal)/Inha/5_Lectures/Advanced metagenomics/scripts/IBS7048_Advanced_metagenomics/"
path_library <- "/Library/Frameworks/R.framework/Resources/library"
str_libraries <- c("tidyverse", "pacman", "yaml", "knitr", "rmarkdown", "rmdformats")


YAML_header <-
        '---
title: "COD_20231115_MGK_IBS7048_week12_DA_analysis"
author: "Minsik Kim"
date: "2032.11.15"
output:
    rmdformats::downcute:
        downcute_theme: "chaos"
        codeolding: hide
        fig_width: 6
        fig_height: 6
---'
seed <- "20230920"

#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
#Loads libraries, file paths, and other document options.
#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
FUN.LineZero.Boot <- function() {
        .libPaths(path_library)
        
        require(pacman)
        pacman::p_load(c("knitr", "rmarkdown", "rmdformats", "yaml","ggpubr"))
        
        knitr::opts_knit$set(root.dir = path_working)
        
        str_libraries |> unique() |> sort() -> str_libraries
        pacman::p_load(char = str_libraries)
        
        set.seed(seed)
}
FUN.LineZero.Boot()
#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
#Outputs R environment report.
#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
FUN.LineZero.Report <- function() {
        cat("Line Zero Environment:\n\n")
        paste("R:", pacman::p_version(), "\n") |> cat()
        cat("Libraries:\n")
        for (str_libraries in str_libraries) {
                paste(
                        "    ", str_libraries, ": ", pacman::p_version(package = str_libraries),
                        "\n", sep = ""
                ) |> cat()
        }
        paste("\nOperating System:", pacman::p_detectOS(), "\n") |> cat()
        paste("    Library Path:", path_library, "\n") |> cat()
        paste("    Working Path:", path_working, "\n") |> cat()
        paste("Seed:", seed, "\n\n") |> cat()
        cat("YAML Header:\n")
        cat(YAML_header)
}
FUN.LineZero.Report()


```

This analysis pipe noted https://github.com/minsiksudo/BTE3207_Advanced_Biostatistics.


# Roading the data

from previous lecture.. we generated a phyloseq object. it can be saved to hard disk using the below command.

`saveRDS(ps, "phyloseq_example.rds")`

And it can be loaded to a new R session like below!

```{r}

getwd()

library(phyloseq)
library(tidyverse)
library(microbiome)
library(vegan)
library(ggplot2)
#source("https://raw.githubusercontent.com/joey711/phyloseq/master/inst/scripts/installer.R",
#       local = TRUE)


phyloseq <- readRDS("/Users/minsikkim/Dropbox (Personal)/Inha/5_Lectures/Advanced metagenomics/scripts/IBS7048_Advanced_metagenomics/phyloseq_example.rds")


phyloseq_rel <- transform_sample_counts(phyloseq,
                                        function(x){x/sum(x)})
```

# Recall

From the barplot...

```{r}
# Create a df with all `Top 10 Genus` and flag the top 20


plot_bar(phyloseq_rel, fill = "Genus") +
        ylab("Total read counts") +
        theme_classic() +
        theme(axis.text.x = element_text(angle = 90),
              legend.position = "none") +
        #scale_fill_brewer(type = "qual", palette = 3) +
        facet_wrap(~When, scales = "free") +
        ggtitle("Microbiome composition by sampling event time")
        


cowplot::get_legend(
plot_bar(phyloseq_rel, fill = "Genus") +
        ylab("Total read counts") +
        theme_classic() +
        theme(axis.text.x = element_text(angle = 90)) +
        labs(fill = "ASVs and their Genus") +
        #scale_fill_brewer(type = "qual", palette = 3) +
        facet_wrap(~When, scales = "free") +
        ggtitle("Microbiome composition by sampling event time")
) %>%
        ggpubr::as_ggplot()
        
        
        
```

Can you see the difference? 



# Differential abundance analysis using your model

## Using linear models 1


```{r}


#Loading OTU table

otu_table <- phyloseq_rel %>% otu_table %>% t
        
#tax table for different sample type
taxa_data <- otu_table[1] %>% t %>% data.frame()

#Making a merged dataframe having sample data and CLR transformed output
lme_data <- merge(taxa_data, sample_data(phyloseq_rel), by = 0) %>% column_to_rownames("Row.names")


ggplot(lme_data, aes(x = Day, y = ASV1)) +
        geom_point()


```

It looks like ther is some difference (in ther relative abundacnes)

Can we test them?

```{r}

lm(ASV1 ~ When, data = lme_data) %>%
        summary()
 

```

THe difference is not significant

## Using linear models 2

How does it look like with the second ASV

```{r}


#Loading OTU table

otu_table <- phyloseq_rel %>% otu_table %>% t
        
#tax table for different sample type
taxa_data <- otu_table[2] %>% t %>% data.frame()

#Making a merged dataframe having sample data and CLR transformed output
lme_data <- merge(taxa_data, sample_data(phyloseq_rel), by = 0) %>% column_to_rownames("Row.names")


ggplot(lme_data, aes(x = Day, y = ASV2)) +
        geom_point()
```

How about statistics?

```{r}

lm(ASV2 ~ When, data = lme_data) %>%
        summary()
 

```

No difference...

# Can we run all the statistical test at once?

## Introduction to for loop

```{r}

for(i in 1:10) {
        print(i)
}


```


```{r}

x = 0

for(i in 1:10) {
        x <- x + i
        print(x + i)
}

x


```

## For-loop for analysis result 

THis is the example code for running lm test for the 1st ASV.

```{r}

#with all samples

lm_taxa_all <- data.frame()

for(i in 1:1) {
        #Creating a data frame that includes CLR transformed data of i-th bug.
        #making differnt otu tables for each sample type
        otu_table <- phyloseq_rel %>% otu_table
        
        #tax table for different sample type
        taxa_data <- otu_table[,i] %>% data.frame()
        
        #Making a merged dataframe having sample data and CLR transformed output
        lm_data <- merge(taxa_data, sample_data(phyloseq_rel), by = 0) %>%
                column_to_rownames("Row.names")
        
        #generating a character of formula.
        #Here, as the taxa are already CLR transformed, I did not make model at log-scale.
        lmformula <- paste(names(taxa_data), "~", "When")
        
        #BAL stratified analysis
        all_result <- lm(formula = lmformula,
                                 data = lm_data) %>% 
                summary %>%
                .$coefficients %>%
                data.frame(check.names = F) %>% 
                mutate(feature = names(taxa_data)) %>% 
                rownames_to_column("value") %>%
                .[2,] %>%
                remove_rownames()
        #row binding all the associations of i-th taxa to one data frame
        lm_taxa_all <- rbind(lm_taxa_all,
                               all_result) %>% 
                remove_rownames()
        
}


head(lm_taxa_all)



```

## For-loop for DA analysis

By changing the number of for loop, we can run multiple test and aggregate the result into one dataframe.

```{r}


#with all samples

lm_taxa_all <- data.frame()

all <- phyloseq_rel %>% taxa_sums() %>% length()

for(i in 1:all) {
        #Creating a data frame that includes CLR transformed data of i-th bug.
        #making differnt otu tables for each sample type
        otu_table <- phyloseq_rel %>% otu_table
        
        #tax table for different sample type
        taxa_data <- otu_table[,i] %>% data.frame()
        
        #Making a merged dataframe having sample data and CLR transformed output
        lm_data <- merge(taxa_data, sample_data(phyloseq_rel), by = 0) %>% column_to_rownames("Row.names")
        
        #generating a character of formula.
        #Here, as the taxa are already CLR transformed, I did not make model at log-scale.
        lmformula <- paste(names(taxa_data), "~", "When")
        
        #BAL stratified analysis
        all_result <- lm(formula = lmformula,
                                 data = lm_data) %>% 
                summary %>%
                .$coefficients %>%
                data.frame(check.names = F) %>% 
                mutate(feature = names(taxa_data)) %>% 
                rownames_to_column("value") %>%
                .[2,] %>%
                remove_rownames()
        #row binding all the associations of i-th taxa to one data frame
        lm_taxa_all <- rbind(lm_taxa_all,
                               all_result) %>% 
                remove_rownames()
        
}

head(lm_taxa_all)

```


# Multple testing correction

Since we tested multiple tests at once, the p-value needs to be adjusted


```{r}

lm_taxa_all <- lm_taxa_all %>%
        subset(., !is.nan(.$`Pr(>|t|)`)) %>%
        mutate(qval = qvalue::qvalue(`Pr(>|t|)`, lambda = 0)$qvalue,
               p_bh = p.adjust(p = `Pr(>|t|)`, method = "BH"))  
#Benjamini-Hochberg correction



head(lm_taxa_all)

```

To visualize the output.

volcano plot

```{r}

ggplot(lm_taxa_all, aes(x = Estimate, y = -log10(p_bh))) +
        geom_point() +
        geom_hline(yintercept = -log10(0.05), col = "red") +
        annotate("text", x = 0.05, y = 1.5, label = "p-value = 0.05", col = "red")

```

It looks weird, as we only tested the relative abundance!

## For-loop for DA analysis (transformed data)

We can make CLR transfomred data, to consider the caveat of relative abundance

```{r}

phyloseq_clr <- microbiome::transform(phyloseq, transform = "clr")

#with all samples

lm_taxa_all <- data.frame()

all <- phyloseq_clr %>% taxa_sums() %>% length()

for(i in 1:all) {
        #Creating a data frame that includes CLR transformed data of i-th bug.
        #making differnt otu tables for each sample type
        otu_table <- phyloseq_clr %>% otu_table
        
        #tax table for different sample type
        taxa_data <- otu_table[,i] %>% data.frame()
        
        #Making a merged dataframe having sample data and CLR transformed output
        lm_data <- merge(taxa_data, sample_data(phyloseq_clr), by = 0) %>% column_to_rownames("Row.names")
        
        #generating a character of formula.
        #Here, as the taxa are already CLR transformed, I did not make model at log-scale.
        lmformula <- paste(names(taxa_data), "~", "When")
        
        #BAL stratified analysis
        all_result <- lm(formula = lmformula,
                                 data = lm_data) %>% 
                summary %>%
                .$coefficients %>%
                data.frame(check.names = F) %>% 
                mutate(feature = names(taxa_data)) %>% 
                rownames_to_column("value") %>%
                .[2,] %>%
                remove_rownames()
        #row binding all the associations of i-th taxa to one data frame
        lm_taxa_all <- rbind(lm_taxa_all,
                               all_result) %>% 
                remove_rownames()
        
}



lm_taxa_all <- lm_taxa_all %>%
        subset(., !is.nan(.$`Pr(>|t|)`)) %>%
        mutate(qval = qvalue::qvalue(`Pr(>|t|)`, lambda = 0)$qvalue,
               p_bh = p.adjust(p = `Pr(>|t|)`, method = "BH"))  
#Benjamini-Hochberg correction



head(lm_taxa_all)

```

volcano plot

```{r}

ggplot(lm_taxa_all, aes(x = Estimate, y = -log10(p_bh))) +
        geom_point() +
        geom_hline(yintercept = -log10(0.05), col = "red") +
        annotate("text", x = 0.05, y = 1.5, label = "p-value = 0.05", col = "red")

```

Volcano plot looks ok.



# Using MaAslin


MaAsLin2 is comprehensive R package for efficiently determining multivariable association between phenotypes, environments, exposures, covariates and microbial metaâ€™omic features. MaAsLin2 relies on general linear models to accommodate most modern epidemiological study designs, including cross-sectional and longitudinal, and offers a variety of data exploration, normalization, and transformation methods.



https://huttenhower.sph.harvard.edu/maaslin/



```{r}

if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("Maaslin2")
BiocManager::install("qvalue")
BiocManager::install("SIAMCAT")



library(Maaslin2)


```

Running maaslin

```{r}
capture.output(
        maaslin_output<-
                Maaslin2(input_data = otu_table(phyloseq_rel) %>% 
                                 data.frame(),
                         input_metadata = phyloseq_rel %>%
                                 sample_data %>% 
                                 data.frame(check.names = F), 
                output = paste0(getwd(), "/maaslin_output") ,
                fixed_effects = c("When"), 
                transform = "LOG", #default
                normalization = "TSS", #Choose your own normalization method
                reference = c("When,Early")))

maaslin_all <- read.csv(paste0(getwd(), "/maaslin_output/all_results.tsv"), sep = "\t")

head(maaslin_all)



```

Volcano plot of MaAslin output

```{r}

ggplot(maaslin_all, aes(x = coef, y = -log10(qval))) +
        geom_point() +
        geom_hline(yintercept = -log10(0.05), col = "red") +
        annotate("text", x = 0.1, y = 1.5, label = "q-value = 0.1", col = "red")

```

```{r}

install.packages("devtools")
library(devtools)

devtools::install_github("slowkow/ggrepel")


library(ggrepel)

ggplot(maaslin_all, aes(x = coef, y = -log10(qval))) +
        geom_point() +
        geom_hline(yintercept = -log10(0.05), col = "red") +
        annotate("text", x = 0.1, y = 1.5, label = "q-value = 0.1", col = "red") +
        geom_text_repel(aes(label = feature)) +
        theme_classic()    

```

# Using SIAMCAT

Due to limited number of samples / metadat in our dataset, we are going to use examples et from SIAMCAT pacakge.

**https://siamcat.embl.de/articles/SIAMCAT_vignette.html*

```{r}

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("SIAMCAT")

#or,

#require("devtools")
#devtools::install_github(repo = 'zellerlab/siamcat')

library(SIAMCAT)

```

Loading example data set

```{r}


data("feat_crc_zeller", package="SIAMCAT")
data("meta_crc_zeller", package="SIAMCAT")

siamcat_feature <- feat.crc.zeller
siamcat_meta <- meta.crc.zeller


```

Please note that SIAMCAT is supposed to work with relative abundances. Other types of data (e.g. counts) will also work, but not all functions of the package will result in meaningful outputs.


Checking dimensions of SIAMCAT

```{r}

dim(siamcat_feature)

```

Generating labels for SIAMCAT analysis


```{r}
siamcat_label <- create.label(meta=siamcat_meta,
    label='Group', case='CRC')

head(siamcat_label)
```

Creating a SIAMCAT object

```{r}

sc.obj <- siamcat(feat=siamcat_feature,
    label=siamcat_label,
    meta=siamcat_meta)

sc.obj

```

Filtering low abundant taxta

```{r}

sc.obj <- filter.features(sc.obj,
    filter.method = 'abundance',
    cutoff = 0.001)

```

Testing associations

Associations between microbial species and the label can be tested with the check.associations function. The function computes for each species the significance using a non-parametric Wilcoxon test and different effect sizes for the association (e.g. AUC or fold change).


The function produces a pdf file as output, since the plot is optimized for a landscape DIN-A4 layout, but can also used to plot on an active graphic device, e.g. in RStudio. The resulting plot then looks like that:

```{r}
sc.obj <- check.associations(sc.obj, log.n0 = 1e-06, alpha = 0.05)

association.plot(sc.obj, sort.by = 'fc', 
                panels = c('fc', 'prevalence', 'auroc'))
```

Confounder testing


```{r}

check.confounders(sc.obj, fn.plot = 'confounder_plots.pdf',
                    meta.in = NULL, feature.type = 'filtered')

```

Data normalization

```{r}

sc.obj <- normalize.features(sc.obj, norm.method = "log.unit",
    norm.param = list(log.n0 = 1e-06, n.p = 2,norm.margin = 1))

```

Cross-validation preparing


```{r}
sc.obj <-  create.data.split(sc.obj, num.folds = 5, num.resample = 2)

```

Training model using *lasso* (least absolute shrinkage and selection operator; also Lasso or LASSO), a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the resulting statistical model. 


*Lasso* is a supervised regularization method used in *machine learning*.

`method = ` specifies the type of model to be trained, may be one of these:

`c('lasso', 'enet', 'ridge', 'lasso_ll', 'ridge_ll', 'randomForest')`



```{r}
#Model training
sc.obj.lasso <- train.model(sc.obj, method = "lasso")

```


Model evaluation

This function calculates the Area Under the Receiver Operating Characteristic (ROC) Curve (AU-ROC) )and the Precision Recall (PR) Curve for each resampled cross-validation run.

```{r}
#Making predictions
sc.obj.lasso <- make.predictions(sc.obj.lasso)
sc.obj.lasso <-  evaluate.predictions(sc.obj.lasso)
model.evaluation.plot(sc.obj.lasso)

```

Making interpretation plot

```{r}
model.interpretation.plot(sc.obj.lasso, fn.plot = 'interpretation.pdf',
    consens.thres = 0.5, limits = c(-3, 3), heatmap.type = 'zscore')

```

# Bibliography

```{r warning=FALSE, message=FALSE, echo=FALSE}
#===============================================================================
#BTC.LineZero.Footer.1.1.0
#===============================================================================
#R markdown citation generator.
#===============================================================================
#RLB.Dependencies:
#   magrittr, pacman, stringr
#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
#BTC.Dependencies:
#   LineZero.Header
#===============================================================================
#Generates citations for each explicitly loaded library.
#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
str_libraries <- c("r", str_libraries)
for (str_libraries in str_libraries) {
        str_libraries |>
                pacman::p_citation() |>
                print(bibtex = FALSE) |>
                capture.output() %>%
                .[-1:-3] %>% .[. != ""] |>
                stringr::str_squish() |>
                stringr::str_replace("_", "") |>
                cat()
        cat("\n")
}
#===============================================================================
```